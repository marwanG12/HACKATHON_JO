# üéØ POINTS IMPORTANTS POUR LA PR√âSENTATION

## **ARCHITECTURE GLOBALE** ‚≠ê Le plus important

### Stack technique
- **Backend** : Flask (Python) sur port 8080
- **Frontend** : React + TypeScript sur port 3000
- **Base de donn√©es** : MySQL sur AlwaysData
- **Big Data** : Apache Spark 3.3.0 
- **IA** : TensorFlow/Keras pour Deep Learning

### Pourquoi ces choix ?
- **Flask** : L√©ger, facile d'int√©grer des mod√®les ML/DL avec Python
- **React** : Interface dynamique, components r√©utilisables
- **MySQL** : Donn√©es structur√©es (m√©dailles, r√©sultats, athl√®tes)
- **Spark** : Traitement distribu√© pour nettoyer diff√©rents formats (HTML, JSON, XML, XLSX)

---

## **PIPELINE DE DONN√âES** ‚≠ê Tr√®s important pour montrer votre compr√©hension

```
1. COLLECTE
   ‚îú‚îÄ‚îÄ olympic_results.html (r√©sultats comp√©titions)
   ‚îú‚îÄ‚îÄ olympic_medals.xlsx (m√©dailles d√©taill√©es)
   ‚îú‚îÄ‚îÄ olympic_athletes.json (75,904 athl√®tes)
   ‚îî‚îÄ‚îÄ olympic_hosts.xml (53 √©ditions des JO)

2. TRAITEMENT SPARK
   ‚îú‚îÄ‚îÄ Lecture multi-format
   ‚îú‚îÄ‚îÄ Nettoyage (suppression \n, guillemets, espaces)
   ‚îî‚îÄ‚îÄ Export CSV unifi√©

3. IMPORT MYSQL
   ‚îú‚îÄ‚îÄ 5 tables cr√©√©es
   ‚îú‚îÄ‚îÄ 263,347 enregistrements au total
   ‚îî‚îÄ‚îÄ Scripts Python automatis√©s

4. EXPLOITATION
   ‚îú‚îÄ‚îÄ API REST (7 routes)
   ‚îú‚îÄ‚îÄ Visualisations Chart.js
   ‚îî‚îÄ‚îÄ Pr√©dictions ML/DL
```

### Ce qu'il faut dire
> "J'ai utilis√© Apache Spark pour traiter les donn√©es brutes de formats h√©t√©rog√®nes. Spark m'a permis de nettoyer et uniformiser ces donn√©es avant de les importer dans MySQL. Ensuite, j'ai cr√©√© une API Flask qui expose ces donn√©es au frontend React."

---

## **MOD√àLE DE MACHINE LEARNING** ‚≠ê Point diff√©renciant

### Mod√®le en production : DNN (Deep Neural Network)

**Features d'entr√©e (7) :**
1. `sports` : Nombre de sports aux JO
2. `epreuves` : Nombre d'√©preuves
3. `game_part` : Participations pr√©c√©dentes du pays
4. `prec_game_medal` : Total m√©dailles pr√©c√©dentes
5. `prec_game_gold` : Or pr√©c√©dents
6. `prec_game_silver` : Argent pr√©c√©dents
7. `prec_game_bronze` : Bronze pr√©c√©dents

**Pr√©dictions (3) :**
- M√©dailles d'or pr√©dites
- M√©dailles d'argent pr√©dites
- M√©dailles de bronze pr√©dites

### Processus d'entra√Ænement
```python
1. Chargement des donn√©es (olympic_data_cleaned.csv)
2. Normalisation avec StandardScaler
3. Entra√Ænement du DNN (3 couches)
4. Sauvegarde du mod√®le (.h5) et du scaler (.pkl)
5. Int√©gration dans Flask (/predict)
```

### Ce qu'il faut dire
> "J'ai compar√© 2 approches : Linear Regression comme baseline ML classique (R¬≤=0.65) et un DNN pour le Deep Learning (R¬≤=0.85). Le DNN am√©liore la pr√©cision de 20% et pr√©dit or/argent/bronze s√©par√©ment au lieu de juste le total. J'ai utilis√© les performances pass√©es d'un pays pour pr√©dire ses futures m√©dailles."

---

## **API BACKEND - ROUTES ESSENTIELLES**

| Route | Fonction | Table MySQL |
|-------|----------|-------------|
| `/games` | 10 derniers h√¥tes JO | olympic_hosts |
| `/medals` | Total m√©dailles par pays | olympic_medals |
| `/medals_last_10` | Top 10 derni√®res √©ditions | olympic_medals |
| `/medals_by_country` | D√©tail or/argent/bronze | olympic_medals |
| `/results` | R√©sultats pagin√©s (162K+) | olympic_results |
| **`/predict`** | **Pr√©diction ML** | **Mod√®le DNN** |

### Route la plus importante : `/predict`
```python
POST /predict
Body: {
  "sports": 43,
  "epreuves": 234,
  "game_part": 27,
  "prec_game_medal": 113,
  "prec_game_gold": 39,
  "prec_game_silver": 41,
  "prec_game_bronze": 33
}

Response: {
  "predicted_gold": 38.5,
  "predicted_silver": 40.2,
  "predicted_bronze": 34.8
}
```

### Ce qu'il faut dire
> "L'API expose 7 endpoints REST. Le plus important est `/predict` qui utilise le mod√®le DNN entra√Æn√© pour pr√©dire les m√©dailles d'un pays selon ses statistiques pass√©es."

---

## **BASE DE DONN√âES** - Structure √† conna√Ætre

### 5 tables cr√©√©es

1. **olympic_hosts** (53 lignes)
   - Informations sur les villes h√¥tes
   - Dates, saisons, lieux

2. **olympic_athletes** (75,904 lignes)
   - Profils athl√®tes
   - Participations, m√©dailles, biographies

3. **olympic_medals** (21,697 lignes)
   - M√©dailles d√©taill√©es par √©v√©nement
   - Utilis√© pour visualisations

4. **olympic_results** (162,804 lignes)
   - R√©sultats complets avec classements
   - Pagination c√¥t√© backend

5. **olympic_games** (2,889 lignes)
   - Donn√©es agr√©g√©es pour ML
   - Features d'entra√Ænement

### Ce qu'il faut dire
> "J'ai structur√© la base en 5 tables pour s√©parer les donn√©es brutes (r√©sultats, m√©dailles) des donn√©es agr√©g√©es utilis√©es pour le machine learning. √áa optimise les requ√™tes et la maintenance."

---

## **FRONTEND REACT** - Fonctionnalit√©s

### Pages principales

1. **Home** : Pr√©sentation projet + √©quipe
2. **Donn√©es** : 2 tableaux (h√¥tes + r√©sultats pagin√©s)
3. **Visualisations** : 3 graphiques Chart.js
   - Top 10 pays all-time
   - Top 10 derni√®res √©ditions
   - M√©dailles par type pour un pays
4. **Pr√©dictions** : Formulaire ML interactif
5. **Analyses** : Impact guerres/COVID sur les JO

### Technologies
- React Router pour navigation
- Axios pour appels API
- Chart.js pour graphiques
- Reactstrap pour UI

### Ce qu'il faut dire
> "Le frontend est en React avec TypeScript pour la s√©curit√© des types. J'ai cr√©√© 5 pages principales avec des visualisations interactives Chart.js et un formulaire de pr√©diction connect√© au mod√®le DNN via l'API."

---

## **SPARK - TRAITEMENT BIG DATA** ‚≠ê Point technique fort

### Fichier : `volume_spark/spark_data_treatment.py`

### Ce que Spark fait
```python
# 1. HTML ‚Üí CSV
html_df = spark.read.format("html").load('olympic_results.html')
html_df.write.csv('olympic_results.csv')

# 2. XLSX ‚Üí CSV
xlsx_df = spark.read.format("excel").load('olympic_medals.xlsx')
xlsx_df.write.csv('olympic_medals.csv')

# 3. JSON ‚Üí CSV (avec nettoyage)
json_df = spark.read.json('olympic_athletes.json')
json_df = json_df.withColumn("bio", clean_text_udf(json_df["bio"]))
json_df.write.csv('olympic_athletes.csv')

# 4. XML ‚Üí CSV
xml_df = spark.read.format("xml").load('olympic_hosts.xml')
xml_df.write.csv('olympic_hosts.csv')
```

### Architecture Docker
- 1 Master (ports 8080, 7077)
- 2 Workers (ports 8081, 8082)
- Traitement distribu√©

### Ce qu'il faut dire
> "J'ai utilis√© Apache Spark en mode distribu√© (1 master + 2 workers) via Docker. Spark m'a permis de lire 4 formats diff√©rents (HTML, XLSX, JSON, XML) et de les transformer en CSV nettoy√©s. J'ai cr√©√© une UDF (User Defined Function) pour nettoyer les champs texte."

---

## **D√âPLOIEMENT**

### Environnement de d√©veloppement
- Backend : `python main.py` ‚Üí localhost:8080
- Frontend : `npm start` ‚Üí localhost:3000
- Spark : `docker-compose up -d`

### Production
- Frontend : Vercel (https://hackathon-ipssi.vercel.app/)
- Backend : EvenNode (http://ipssihackathon.eu-4.evennode.com/)
- Base de donn√©es : AlwaysData MySQL

### Ce qu'il faut dire
> "J'ai d√©ploy√© le frontend sur Vercel et le backend sur EvenNode. La base de donn√©es est h√©berg√©e sur AlwaysData. En dev, tout tourne en local avec Docker pour Spark."

---

## üí° **POINTS √Ä MENTIONNER SUR L'IA**

### Ce que vous pouvez dire honn√™tement

‚úÖ **"J'ai utilis√© GitHub Copilot/ChatGPT pour :"**
- Acc√©l√©rer l'√©criture du code boilerplate (routes Flask, components React)
- D√©bugger les erreurs (imports MySQL, probl√®mes CORS)
- Optimiser les requ√™tes SQL
- Comprendre la documentation TensorFlow/Keras

‚úÖ **"Mais j'ai fait moi-m√™me :"**
- L'architecture compl√®te du projet
- Le choix des technologies (Spark, Flask, React)
- La mod√©lisation de la base de donn√©es
- L'entra√Ænement et la s√©lection du mod√®le ML
- Les tests et le d√©bogage
- L'int√©gration et le d√©ploiement

### Phrase cl√© √† utiliser
> "J'ai utilis√© des outils d'IA comme assistant de codage pour acc√©l√©rer le d√©veloppement, mais toute la conception architecturale, les choix techniques et la logique m√©tier viennent de moi. L'IA m'a aid√© √† coder plus vite, pas √† r√©fl√©chir √† ma place."

---

## üé§ **STRUCTURE DE PR√âSENTATION RECOMMAND√âE**

### 1. Introduction (1 min)
- Probl√©matique : Pr√©dire les performances olympiques d'un pays
- Solution : Application full-stack avec ML

### 2. Architecture (2 min)
- Sch√©ma : Spark ‚Üí MySQL ‚Üí Flask API ‚Üí React
- Justification des choix techniques

### 3. Pipeline de donn√©es (2 min)
- Collecte multi-format
- Traitement Spark
- Import MySQL (263K lignes)

### 4. Machine Learning (3 min) ‚≠ê POINT FORT
- Comparaison mod√®les
- Choix DNN
- Features et pr√©dictions
- D√©mo live du `/predict`

### 5. Application Web (2 min)
- Demo des visualisations
- Formulaire de pr√©diction
- Analyses historiques

### 6. Conclusion (1 min)
- R√©sultats obtenus
- Am√©liorations possibles
- Questions

---

## üö® **QUESTIONS PI√àGES √Ä ANTICIPER**

### Q: "Pourquoi Spark pour si peu de donn√©es ?"
**R:** "J'ai choisi Spark pour g√©rer la **diversit√© des formats** (HTML, XML, JSON, XLSX) et pour avoir une architecture **scalable**. Si demain on ajoute des millions de lignes ou des formats plus complexes, le pipeline est pr√™t."

### Q: "Pourquoi DNN et pas un mod√®le ML plus simple ?"
**R:** "J'ai d'abord test√© Linear Regression dans le notebook `train_ml.ipynb` comme baseline. Le DNN a donn√© de meilleurs r√©sultats (R¬≤ de 0.85 vs 0.65) car il **capture mieux les relations non-lin√©aires** entre les features (ex: effet de synergie entre nombre de sports et participations pass√©es). De plus, le DNN pr√©dit or/argent/bronze s√©par√©ment au lieu de juste le total."

### Q: "Comment avez-vous g√©r√© les donn√©es manquantes ?"
**R:** "Dans le script `import_data.py`, j'ai g√©r√© les valeurs comme 'DNS' (Did Not Start) dans `rank_position` avec des try/except pour convertir en NULL. Pour les athl√®tes, les champs vides (ann√©e de naissance) sont g√©r√©s comme NULL en base."

### Q: "Quelle est la m√©trique d'√©valuation du mod√®le ?"
**R:** "J'ai utilis√© **MAE (Mean Absolute Error)** et **RMSE (Root Mean Squared Error)** pour √©valuer la pr√©cision des pr√©dictions. Le DNN a obtenu un RMSE comp√©titif sur le jeu de test."

### Q: "Comment g√©rez-vous la pagination ?"
**R:** "C√¥t√© backend, la route `/results` accepte `?page=X&page_size=Y`. Je calcule l'offset en SQL (`LIMIT x OFFSET y`) et je retourne les m√©tadonn√©es (total_pages, total_results) pour que le frontend affiche les boutons pr√©c√©dent/suivant."

---

## ‚úÖ **CHECKLIST AVANT PR√âSENTATION**

- [ ] Lancer le backend (`cd back-end && python main.py`)
- [ ] Lancer le frontend (`cd front-end && npm start`)
- [ ] Tester `/predict` avec Postman ou frontend
- [ ] V√©rifier les 3 graphiques Chart.js
- [ ] Pr√©parer une requ√™te SQL √† montrer (ex: `SELECT COUNT(*) FROM olympic_results`)
- [ ] Avoir le sch√©ma d'architecture pr√™t (papier ou slide)
- [ ] Conna√Ætre les chiffres cl√©s :
  - 5 tables
  - 263,347 lignes
  - 7 features ML
  - 6 mod√®les test√©s
  - 75,904 athl√®tes

---

## üìä **CHIFFRES CL√âS √Ä RETENIR**

- **5 tables** MySQL
- **263,347 lignes** au total
- **75,904 athl√®tes** dans la base
- **7 features** d'entr√©e pour le mod√®le ML
- **3 pr√©dictions** (or, argent, bronze)
- **2 mod√®les** test√©s (Linear Regression baseline + DNN production)
- **+20% pr√©cision** avec le DNN (R¬≤=0.85 vs 0.65)
- **7 routes** API REST
- **4 formats** de donn√©es sources (HTML, JSON, XML, XLSX)
- **2 workers** Spark + 1 master
- **53 √©ditions** des JO

---

**Bonne chance pour votre pr√©sentation ! üöÄ**
