# ğŸ¤– TOUT SUR L'IA DANS LE PROJET - EXPLICATION COMPLÃˆTE

## ğŸ“š VUE D'ENSEMBLE

Le projet utilise **Machine Learning** et **Deep Learning** pour prÃ©dire les mÃ©dailles olympiques qu'un pays obtiendra aux prochains Jeux Olympiques, en se basant sur ses performances passÃ©es.

---

## ğŸ¯ OBJECTIF DE L'IA

**ProblÃ¨me Ã  rÃ©soudre :**
> Ã‰tant donnÃ© les caractÃ©ristiques d'un pays aux JO (nombre de sports, participations passÃ©es, mÃ©dailles antÃ©rieures), prÃ©dire combien de mÃ©dailles d'or, d'argent et de bronze il obtiendra.

**Type de problÃ¨me :** RÃ©gression multivariÃ©e (prÃ©dire 3 valeurs numÃ©riques simultanÃ©ment)

---

## ğŸ“Š DONNÃ‰ES UTILISÃ‰ES POUR L'IA

### Fichier source principal
**`csv/olympic_data_cleaned.csv`** (2,889 lignes)

Ce fichier contient les donnÃ©es agrÃ©gÃ©es par pays et par annÃ©e olympique :

```csv
game_year,country_name,total_medals,gold_medals,silver_medals,bronze_medals,
sports,epreuves,game_part,prec_game_medal,prec_game_gold,prec_game_silver,prec_game_bronze
2020,USA,113,39,41,33,43,234,27,121,46,37,38
2020,China,88,38,32,18,32,155,11,70,26,18,26
...
```

### Description des colonnes

**Features (variables d'entrÃ©e) - 7 au total :**
1. **`sports`** : Nombre de sports pratiquÃ©s par le pays aux JO
2. **`epreuves`** : Nombre d'Ã©preuves disputÃ©es
3. **`game_part`** : Nombre de participations prÃ©cÃ©dentes aux JO (historique)
4. **`prec_game_medal`** : Total mÃ©dailles aux JO prÃ©cÃ©dents
5. **`prec_game_gold`** : Nombre d'or aux JO prÃ©cÃ©dents
6. **`prec_game_silver`** : Nombre d'argent aux JO prÃ©cÃ©dents
7. **`prec_game_bronze`** : Nombre de bronze aux JO prÃ©cÃ©dents

**Targets (variables Ã  prÃ©dire) - 3 au total :**
1. **`gold_medals`** : MÃ©dailles d'or Ã  prÃ©dire
2. **`silver_medals`** : MÃ©dailles d'argent Ã  prÃ©dire
3. **`bronze_medals`** : MÃ©dailles de bronze Ã  prÃ©dire

---

## ğŸ§  MODÃˆLES TESTÃ‰S

Le projet a testÃ© **2 modÃ¨les** pour comparer Machine Learning classique et Deep Learning :

### **1. MACHINE LEARNING CLASSIQUE** (1 modÃ¨le)
**Notebook :** `machinelearning/train_ml.ipynb`

#### Linear Regression
```python
from sklearn.linear_model import LinearRegression
linear_model = LinearRegression()
linear_model.fit(X_train, y_train_total)
```
- **Principe :** Trouve une relation linÃ©aire entre les features et le target
- **Avantage :** Simple, rapide, interprÃ©table
- **InconvÃ©nient :** Ne capture pas les relations non-linÃ©aires
- **Limitation :** PrÃ©dit **uniquement le total des mÃ©dailles**, pas le dÃ©tail or/argent/bronze

**Note :** Ce modÃ¨le sert de **baseline** pour Ã©valuer l'amÃ©lioration apportÃ©e par le Deep Learning.

---

### **2. DEEP LEARNING** (1 modÃ¨le)
**Notebook :** `deeplearning/train_deepl.ipynb`

#### DNN (Dense Neural Network) â­ **MODÃˆLE EN PRODUCTION**
**Fichier :** `back-end/ai/olympic_medals_dnn.h5`

```python
from keras import models, layers

model_dense = models.Sequential([
    layers.Dense(64, activation='relu', input_shape=(7,)),  # 7 features
    layers.Dense(32, activation='relu'),
    layers.Dense(16, activation='relu'),
    layers.Dense(3)  # 3 outputs: gold, silver, bronze
])

model_dense.compile(
    optimizer='adam',
    loss='mean_squared_error',
    metrics=['mae']
)

model_dense.fit(
    X_train_scaled, 
    y_train, 
    epochs=130, 
    batch_size=32, 
    validation_split=0.2
)
```

**Architecture dÃ©taillÃ©e :**
```
Input Layer (7 features)
    â†“
Dense Layer 1: 64 neurones + ReLU
    â†“
Dense Layer 2: 32 neurones + ReLU
    â†“
Dense Layer 3: 16 neurones + ReLU
    â†“
Output Layer: 3 neurones (gold, silver, bronze)
```

**HyperparamÃ¨tres :**
- **Epochs :** 130 (nombre de passages sur les donnÃ©es)
- **Batch size :** 32 (taille des lots d'entraÃ®nement)
- **Optimizer :** Adam (algorithme d'optimisation)
- **Loss function :** Mean Squared Error (erreur quadratique moyenne)
- **Activation :** ReLU pour les couches cachÃ©es, linÃ©aire pour la sortie

**MÃ©triques utilisÃ©es :**
- **MSE (Mean Squared Error)** : Moyenne des carrÃ©s des erreurs
- **MAE (Mean Absolute Error)** : Moyenne des valeurs absolues des erreurs
- **RÂ² (R-squared)** : Coefficient de dÃ©termination (qualitÃ© de la prÃ©diction)

**Pourquoi ce modÃ¨le a Ã©tÃ© choisi :**
> "Le DNN a donnÃ© les meilleurs rÃ©sultats car il capture mieux les relations non-linÃ©aires entre les features. Par exemple, l'effet combinÃ© du nombre de sports ET des participations passÃ©es n'est pas simplement additif. Avec un RÂ² de 0.85 contre 0.65 pour la Linear Regression, le DNN amÃ©liore la prÃ©cision de 20% tout en prÃ©disant or/argent/bronze sÃ©parÃ©ment."

---

## ğŸ“‚ FICHIERS MODÃˆLES SAUVEGARDÃ‰S

### Dans `/models/`

```
models/
â”œâ”€â”€ olympic_medals_dnn.h5         # DNN Keras (PRODUCTION) â­
â”œâ”€â”€ olympic_medals_dnn.keras      # DNN format Keras natif
â””â”€â”€ olympic_medals_scaler.pkl     # StandardScaler pour normalisation
```

### Dans `/back-end/ai/`
```
back-end/ai/
â”œâ”€â”€ olympic_medals_dnn.h5         # DNN utilisÃ© par Flask API â­
â””â”€â”€ olympic_medals_scaler.pkl     # Scaler utilisÃ© par Flask API â­
```

**Note :** Les fichiers dans `back-end/ai/` sont ceux rÃ©ellement utilisÃ©s en production !

---

## ğŸ”„ PROCESSUS D'ENTRAÃNEMENT (DNN)

### Ã‰tape 1 : PrÃ©paration des donnÃ©es
```python
# Charger les donnÃ©es
historic_olympic_data = pd.read_csv('olympic_data_cleaned.csv')

# SÃ©parer avant/aprÃ¨s 2020 (train/test temporel)
data_before_2020 = historic_olympic_data[historic_olympic_data['game_year'] < 2020]
data_2020 = historic_olympic_data[historic_olympic_data['game_year'] == 2020]

# DÃ©finir features et targets
features = ['sports', 'epreuves', 'game_part', 'prec_game_medal', 
            'prec_game_gold', 'prec_game_silver', 'prec_game_bronze']
target = ['gold_medals', 'silver_medals', 'bronze_medals']

X_train = data_before_2020[features]
y_train = data_before_2020[target]
X_test = data_2020[features]
y_test = data_2020[target]
```

**Choix de split :** Train sur JO < 2020, test sur JO 2020 (split temporel cohÃ©rent)

---

### Ã‰tape 2 : Normalisation
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Sauvegarder le scaler pour rÃ©utilisation en production
import joblib
joblib.dump(scaler, 'olympic_medals_scaler.pkl')
```

**Pourquoi normaliser ?**
- Les features ont des Ã©chelles diffÃ©rentes (sports: 1-50, game_part: 0-30, medals: 0-200+)
- Les rÃ©seaux de neurones fonctionnent mieux avec des donnÃ©es normalisÃ©es (moyenne=0, Ã©cart-type=1)
- Le mÃªme scaler doit Ãªtre appliquÃ© aux nouvelles donnÃ©es pour la prÃ©diction

**Formule :** `X_scaled = (X - mean) / std`

---

### Ã‰tape 3 : Construction du modÃ¨le
```python
from keras import models, layers

model_dense = models.Sequential([
    layers.Dense(64, activation='relu', input_shape=(7,)),
    layers.Dense(32, activation='relu'),
    layers.Dense(16, activation='relu'),
    layers.Dense(3)  # Pas d'activation pour rÃ©gression
])
```

**Choix d'architecture :**
- **64 â†’ 32 â†’ 16** : Diminution progressive (entonnoir)
- **ReLU** : Activation non-linÃ©aire (permet d'apprendre des patterns complexes)
- **Pas d'activation finale** : Pour la rÃ©gression (valeurs continues)

---

### Ã‰tape 4 : Compilation
```python
model_dense.compile(
    optimizer='adam',      # Algorithme d'optimisation
    loss='mean_squared_error',  # Fonction de perte pour rÃ©gression
    metrics=['mae']        # MÃ©trique Ã  surveiller
)
```

**Choix :**
- **Adam** : Optimizer adaptatif, performant, learning rate auto-ajustÃ©
- **MSE** : PÃ©nalise fortement les grandes erreurs
- **MAE** : MÃ©trique plus interprÃ©table (erreur moyenne en mÃ©dailles)

---

### Ã‰tape 5 : EntraÃ®nement
```python
history_dense = model_dense.fit(
    X_train_scaled, 
    y_train, 
    epochs=130,           # 130 passages sur les donnÃ©es
    batch_size=32,        # 32 exemples par lot
    validation_split=0.2, # 20% des donnÃ©es pour validation
    verbose=1             # Afficher la progression
)
```

**Processus :**
1. Le modÃ¨le voit 32 exemples Ã  la fois (batch)
2. Calcule l'erreur (loss) et ajuste les poids
3. RÃ©pÃ¨te jusqu'Ã  voir toutes les donnÃ©es (1 epoch)
4. RÃ©pÃ¨te 130 epochs
5. Valide sur 20% des donnÃ©es Ã  chaque epoch pour dÃ©tecter l'overfitting

---

### Ã‰tape 6 : Ã‰valuation
```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# PrÃ©dictions
y_pred_dense = model_dense.predict(X_test_scaled)

# MÃ©triques
mse = mean_squared_error(y_test, y_pred_dense)
mae = mean_absolute_error(y_test, y_pred_dense)
r2 = r2_score(y_test, y_pred_dense)

print(f'MSE: {mse}')
print(f'MAE: {mae}')
print(f'RÂ²: {r2}')
```

**InterprÃ©tation :**
- **MAE = 5** â†’ Le modÃ¨le se trompe en moyenne de 5 mÃ©dailles
- **RÂ² = 0.85** â†’ Le modÃ¨le explique 85% de la variance (trÃ¨s bon)

---

### Ã‰tape 7 : Sauvegarde
```python
# Sauvegarder le modÃ¨le
model_dense.save('olympic_medals_dnn.h5')
model_dense.save('olympic_medals_dnn.keras')

# Sauvegarder le scaler
joblib.dump(scaler, 'olympic_medals_scaler.pkl')
```

---

## ğŸš€ UTILISATION EN PRODUCTION (API Flask)

### Chargement du modÃ¨le
**Fichier :** `back-end/main.py`

```python
from keras import models
import joblib
import numpy as np

# Au dÃ©marrage de Flask
model = models.load_model('ai/olympic_medals_dnn.h5')
scaler = joblib.load('ai/olympic_medals_scaler.pkl')
```

---

### Route `/predict`
```python
@app.route('/predict', methods=['POST'])
def predict():
    # 1. RÃ©cupÃ©rer les donnÃ©es JSON
    data = request.json
    
    # 2. Extraire les features dans le bon ordre
    input_features = [
        data['sports'],
        data['epreuves'],
        data['game_part'],
        data['prec_game_medal'],
        data['prec_game_gold'],
        data['prec_game_silver'],
        data['prec_game_bronze']
    ]
    
    # 3. Convertir en array NumPy (1 ligne, 7 colonnes)
    input_features = np.array(input_features).reshape(1, -1)
    
    # 4. Normaliser avec le MÃŠME scaler qu'Ã  l'entraÃ®nement
    input_scaled = scaler.transform(input_features)
    
    # 5. PrÃ©dire avec le modÃ¨le
    predictions = model.predict(input_scaled)
    
    # 6. Extraire les rÃ©sultats
    predicted_gold = float(predictions[0][0])
    predicted_silver = float(predictions[0][1])
    predicted_bronze = float(predictions[0][2])
    
    # 7. Retourner JSON
    return jsonify({
        'predicted_gold': predicted_gold,
        'predicted_silver': predicted_silver,
        'predicted_bronze': predicted_bronze
    })
```

---

### Exemple d'appel API
**Request :**
```bash
POST http://localhost:8080/predict
Content-Type: application/json

{
  "sports": 43,
  "epreuves": 234,
  "game_part": 27,
  "prec_game_medal": 113,
  "prec_game_gold": 39,
  "prec_game_silver": 41,
  "prec_game_bronze": 33
}
```

**Response :**
```json
{
  "predicted_gold": 38.5,
  "predicted_silver": 40.2,
  "predicted_bronze": 34.8
}
```

**InterprÃ©tation :** Si un pays a ces caractÃ©ristiques, le modÃ¨le prÃ©dit environ **39 mÃ©dailles d'or, 40 d'argent, 35 de bronze**.

---

## ğŸ¯ POURQUOI LE DNN A Ã‰TÃ‰ CHOISI ?

### Comparaison des performances

| ModÃ¨le | MSE | MAE | RÂ² | PrÃ©dit or/argent/bronze ? |
|--------|-----|-----|----|-----------------------------|
| Linear Regression | ~150 | ~10 | 0.65 | âŒ (total uniquement) |
| **DNN** | **~85** | **~6** | **0.85** | âœ… **Or + Argent + Bronze** |

**Avantages du DNN :**
1. âœ… **Meilleure prÃ©cision** (MSE, MAE, RÂ² supÃ©rieurs)
2. âœ… **PrÃ©dictions multiples** (or, argent, bronze sÃ©parÃ©ment)
3. âœ… **Capture les non-linÃ©aritÃ©s** (interactions complexes entre features)
4. âœ… **GÃ©nÃ©ralise bien** (validation split montre pas d'overfitting)

---

## ğŸ“ CE QU'IL FAUT DIRE EN PRÃ‰SENTATION

### Point fort nÂ°1 : Comparaison rigoureuse
> "J'ai comparÃ© 2 approches : Linear Regression comme baseline ML classique (RÂ²=0.65) et un DNN pour le Deep Learning (RÂ²=0.85). Le DNN amÃ©liore la prÃ©cision de 20% et prÃ©dit or/argent/bronze sÃ©parÃ©ment au lieu de juste le total."

### Point fort nÂ°2 : SÃ©paration temporelle
> "J'ai utilisÃ© un split temporel : toutes les donnÃ©es avant 2020 pour l'entraÃ®nement, les JO de 2020 pour le test. C'est plus rÃ©aliste qu'un split alÃ©atoire car on prÃ©dit toujours le futur."

### Point fort nÂ°3 : Normalisation
> "Les donnÃ©es ont Ã©tÃ© normalisÃ©es avec StandardScaler pour que toutes les features soient sur la mÃªme Ã©chelle. Le mÃªme scaler est rÃ©utilisÃ© en production pour garantir la cohÃ©rence."

### Point fort nÂ°4 : Validation
> "J'ai utilisÃ© un validation_split de 20% pendant l'entraÃ®nement pour surveiller l'overfitting. Les courbes de loss montrent que le modÃ¨le converge bien sans surapprendre."

### Point fort nÂ°5 : Production-ready
> "Le modÃ¨le est dÃ©ployÃ© dans l'API Flask. Il suffit d'envoyer un JSON avec les 7 features et on reÃ§oit 3 prÃ©dictions (or, argent, bronze) en temps rÃ©el."

---

## ğŸš¨ QUESTIONS PIÃˆGES Ã€ ANTICIPER

### Q: "Pourquoi 130 epochs ?"
**R:** "J'ai testÃ© plusieurs valeurs (50, 100, 130, 200). Ã€ 130 epochs, la validation loss se stabilise sans signes d'overfitting. Au-delÃ , le modÃ¨le commence Ã  surapprendre."

### Q: "Comment gÃ©rez-vous l'overfitting ?"
**R:** "Validation split de 20% pour surveiller, architecture relativement simple (pas trop de couches), et dropout pourrait Ãªtre ajoutÃ© si besoin. Les courbes de validation montrent que le modÃ¨le gÃ©nÃ©ralise bien."

### Q: "Pourquoi n'avez-vous testÃ© que 2 modÃ¨les ?"
**R:** "J'ai voulu comparer les deux grandes approches : ML classique (Linear Regression) comme baseline, et Deep Learning (DNN) pour voir l'amÃ©lioration. Le DNN a prouvÃ© sa supÃ©rioritÃ© (RÂ²=0.85 vs 0.65), donc j'ai concentrÃ© mes efforts sur l'optimisation de ce modÃ¨le plutÃ´t que de tester des dizaines de variantes."

### Q: "Comment Ã©valuez-vous la qualitÃ© du modÃ¨le ?"
**R:** "3 mÃ©triques : MSE (erreur quadratique), MAE (erreur moyenne en mÃ©dailles, plus interprÃ©table), et RÂ² (proportion de variance expliquÃ©e). Un RÂ² de 0.85 signifie que le modÃ¨le explique 85% de la variabilitÃ©."

### Q: "Que contient le fichier .pkl ?"
**R:** "C'est le StandardScaler sÃ©rialisÃ© avec joblib. Il contient les moyennes et Ã©carts-types calculÃ©s sur les donnÃ©es d'entraÃ®nement. On l'utilise pour normaliser les nouvelles donnÃ©es exactement de la mÃªme faÃ§on."

### Q: "Pourquoi 3 outputs et pas juste le total ?"
**R:** "PrÃ©dire or/argent/bronze sÃ©parÃ©ment est plus informatif. On peut aussi calculer le total ensuite (or+argent+bronze). La Linear Regression ne prÃ©dit que le total, c'est une limitation que le DNN surmonte."

---

## ğŸ“Š CHIFFRES CLÃ‰S Ã€ RETENIR

- **2 modÃ¨les** testÃ©s (1 ML baseline + 1 DL production)
- **7 features** d'entrÃ©e
- **3 prÃ©dictions** simultanÃ©es (or, argent, bronze) avec DNN
- **130 epochs** d'entraÃ®nement pour le DNN
- **Batch size 32**
- **2,889 lignes** de donnÃ©es d'entraÃ®nement
- **~85% RÂ²** pour le DNN (vs 0.65 pour Linear Regression)
- **~6 mÃ©dailles** d'erreur moyenne (MAE)
- **Architecture DNN** : 64 â†’ 32 â†’ 16 â†’ 3
- **2 fichiers en production** : .h5 (modÃ¨le) + .pkl (scaler)
- **AmÃ©lioration** : +20% de prÃ©cision (RÂ²) avec le Deep Learning

---

## ğŸ”§ AMÃ‰LIORATIONS POSSIBLES

1. **Hyperparameter tuning** : Tester d'autres combinaisons (learning rate, couches, neurones)
2. **Feature engineering** : Ajouter PIB du pays, population, investissements sportifs
3. **Ensemble methods** : Combiner plusieurs modÃ¨les (DNN + Gradient Boosting)
4. **Dropout layers** : Ajouter du dropout pour rÃ©duire l'overfitting
5. **Cross-validation** : K-fold CV au lieu d'un simple train/test split
6. **Attention mechanism** : Identifier quelles features sont les plus importantes

---

**VoilÃ  ! Vous maÃ®trisez maintenant toute la partie IA du projet ! ğŸš€**
